# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  jdbc {
    jdbc_connection_string => "${JDBC_CONNECT_STRING}"
    jdbc_user => "${JDBC_USER}"
    jdbc_password => "${JDBC_PASSWORD}"
    jdbc_driver_library => "${LOGSTASH_HOME}/lib/mysql-connector-java/mysql-connector-java-5.1.48-bin.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_paging_enabled => true
    jdbc_page_size => "50000"

    statement_filepath =>"${LOGSTASH_CONFIG}/paper/jdbc-input.sql"

    # statement: ""

    schedule => "0 */5 * * * *"

    # 使用递增列的值
    #use_column_value => true

    # 递增字段的名称，这里使用 update_time 这一列，这列的类型是 timestamp
    #tracking_column => "update_date"

    # 递增字段的类型，numeric 表示数值类型, timestamp 表示时间戳类型
    #tracking_column_type => "timestamp"

    # 同步点文件，这个文件记录了上次的同步点，重启时会读取这个文件，这个文件可以手动修改
    last_run_metadata_path => "${LOGSTASH_LAST_RUN}/paper"

    #clean_run => true

    #type => "file"
  }
}

filter {
  # fetch category
  jdbc_streaming {
    jdbc_driver_library => "${LOGSTASH_HOME}/lib/mysql-connector-java/mysql-connector-java-5.1.48-bin.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "${JDBC_CONNECT_STRING}"
    jdbc_user => "${JDBC_USER}"
    jdbc_password => "${JDBC_PASSWORD}"
    statement => "select wm_object_category.category_id from wm_object_category where wm_object_category.object_id = :object_id and wm_object_category.object_type = :object_type and wm_object_category.domain_id = :domain_id"
    parameters => {
      "object_id" => "id"
      "object_type" => "type"
      "domain_id" => "domain_id"
    }
    target => "category"
  }

  # fetch tag
  jdbc_streaming {
    jdbc_driver_library => "${LOGSTASH_HOME}/lib/mysql-connector-java/mysql-connector-java-5.1.48-bin.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "${JDBC_CONNECT_STRING}"
    jdbc_user => "${JDBC_USER}"
    jdbc_password => "${JDBC_PASSWORD}"
    statement => "select wm_object_tag.tag_id from wm_object_tag where wm_object_tag.object_id = :object_id and wm_object_tag.object_type = :object_type and wm_object_tag.domain_id = :domain_id"
    parameters => {
      "object_id" => "id"
      "domain_id" => "domain_id"
      "object_type" => "type"
    }
    target => "tag"
  }

  mutate {
    add_field => {
      "[@metadata][mode]" => "${LOGSTASH_RUN_MODE:debug}"
      "[@metadata][index]" => "paper"
      "[@metadata][type]" => "social"
    }
    # remove_field => ["tags", "@version", "@timestamp"]
    # copy => { "tag" => "category" }
    # remove_field => [ "type" ]
  }
}

output {
  if [@metadata][mode] == "debug" {
    stdout { }
  }

  if [@metadata][mode] == "prod" {
    elasticsearch {
      hosts => "${ELASTICSEARCH_HOST}"
      index => "mysql-%{[@metadata][type]}-%{[@metadata][index]}"
      document_id => "%{id}"
      pool_max => 100
      pool_max_per_route => 10
      template => "${LOGSTASH_CONFIG}/paper/elasticsearch-template.json"
      template_name => "mysql-social-paper"
      template_overwrite => true
    }
  }
}

