# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
  jdbc {
    jdbc_connection_string => "jdbc:mysql://139.199.76.194:33306/wm_dev?useUnicode=true&allowMultiQueries=true"
    jdbc_user => "user1"
    jdbc_password => "esnP@ssw0rd.17"
    jdbc_driver_library => "../lib/mysql-connector/mysql-connector-java-5.1.23.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_paging_enabled => true
    jdbc_page_size => "50000"

    statement_filepath => "./config/jdbc.sql"

    # statement: ""

    schedule => "* * * * *"

    # 使用递增列的值
    use_column_value => true

    # 递增字段的名称，这里使用 update_time 这一列，这列的类型是 timestamp
    tracking_column => "update_time"

    # 递增字段的类型，numeric 表示数值类型, timestamp 表示时间戳类型
    tracking_column_type => "timestamp"

    # 同步点文件，这个文件记录了上次的同步点，重启时会读取这个文件，这个文件可以手动修改
    last_run_metadata_path => "./logstash_capital_bill_last_id"

    clean_run => true
  }
}

output {
  elasticsearch {
    hosts => "http://localhost:9201"
    index => "mysql-%{+YYYY.MM.dd}-question"
    template_overwrite => true
    #index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
}

# 这里输出调试，正式运行时可以注释掉
stdout {
  codec => json_lines
}
