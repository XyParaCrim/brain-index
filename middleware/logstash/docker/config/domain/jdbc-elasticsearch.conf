input {
  jdbc {
    jdbc_connection_string => "${JDBC_CONNECT_STRING}"
    jdbc_user => "${JDBC_USER}"
    jdbc_password => "${JDBC_PASSWORD}"
    jdbc_driver_library => "${LOGSTASH_HOME}/lib/mysql-connector-java/mysql-connector-java-5.1.48-bin.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_paging_enabled => true
    jdbc_page_size => "50000"

    statement_filepath => "${LOGSTASH_CONFIG}/domain/jdbc-input.sql"

    # 同步点文件，这个文件记录了上次的同步点，重启时会读取这个文件，这个文件可以手动修改
    last_run_metadata_path => "${LOGSTASH_LAST_RUN}/domain"
  }
}
filter {
  mutate {
    add_field => {
      "[@metadata][mode]" => "${LOGSTASH_RUN_MODE:prod}"
      "[@metadata][index]" => "domain"
      "[@metadata][type]" => "portal"
    }
  }
}
output {
 if [@metadata][mode] == "debug" {
   stdout { }
 }
 if [@metadata][mode] == "prod" {
    elasticsearch {
      hosts => "${ELASTICSEARCH_HOST}"
      index => "mysql-%{[@metadata][type]}-%{[@metadata][index]}"
      document_id => "%{domain_id}"
      pool_max => 100
      pool_max_per_route => 10
      template => "${LOGSTASH_CONFIG}/domain/elasticsearch-template.json"
      template_name => "mysql-portal-domain"
      template_overwrite => true
    }
  }
}